{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "extended-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data extraction tools\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Data wrangling tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#DataBase tools\n",
    "import psycopg2\n",
    "import psycopg2.extras as extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-yellow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-gasoline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "monetary-cancer",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "surprising-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_html = None #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "modular-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup(year):\n",
    "    \n",
    "    url = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "    \n",
    "    print(f\"Asking for http content from {url}\")\n",
    "    response = requests.get(url).text\n",
    "    soup = BeautifulSoup(response, \"html.parser\")\n",
    "    \n",
    "    print(f\"Filtering by year provided: {year}...\")\n",
    "    global year_html\n",
    "    year_html = soup.find_all(\"div\", id=f\"faq{year}\")[0] ##############\n",
    "    print(f\"html generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "gentle-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_month_links_df(year, month):\n",
    "    \n",
    "    months_available = [elem.get_text(strip=True) for elem in year_html.find_all(['b'])]\n",
    "    \n",
    "    print(f\"Checking month requested {month} vs months available in the html content...\")\n",
    "    if month not in months_available:\n",
    "        raise ValueError(f\"month provided does not match with available months, check spelling {months_available}\")\n",
    "    \n",
    "    print(f\"Month provided is valid. Filtering by month...\")\n",
    "    filter_by_month = year_html.find(string=f\"{month}\").parent.findNext('ul')\n",
    "    links = [elem.a['href'] for elem in filter_by_month.find_all('li')]\n",
    "    description = [elem.a.text for elem in filter_by_month.find_all('li')]\n",
    "    \n",
    "    single_month_links = pd.DataFrame({'month': month, 'links': links, 'description': description})\n",
    "    \n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    \n",
    "    return single_month_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "collect-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_months_links_df(year, *month):\n",
    "    \n",
    "    links = pd.DataFrame()\n",
    "    \n",
    "    for elem in month:\n",
    "        links = links.append(single_month_links_df(year, elem), ignore_index=True)\n",
    " \n",
    "    print(\"Generating csv links table\")\n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-sharp",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bored-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_lapse(seconds):\n",
    "    seconds_in_day = 60 * 60 * 24\n",
    "    seconds_in_hour = 60 * 60\n",
    "    seconds_in_minute = 60\n",
    "    \n",
    "    days = seconds // seconds_in_day\n",
    "    hours = (seconds - (days * seconds_in_day)) // seconds_in_hour\n",
    "    minutes = (seconds - (days * seconds_in_day) - (hours * seconds_in_hour)) // seconds_in_minute\n",
    "    \n",
    "    return f\"{days} days, {hours} hours, {minutes} minutes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sweet-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_df(year, taxi_color ,*month):\n",
    "    \n",
    "    soup(year) ###\n",
    "    \n",
    "    print(f\"list of months requested: {month}\")\n",
    "    links_table = all_months_links_df(year, *month)\n",
    "    links_table = links_table[links_table['description'].str.contains(taxi_color)][['month','links']]\n",
    "    print(links_table['links'])\n",
    "    \n",
    "    final_df = pd.DataFrame()\n",
    "    \n",
    "    print(\"Starting parsing process:\")\n",
    "    for index, elem in enumerate(links_table['links']):\n",
    "        print(f\"Parsing csv {elem}\")\n",
    "        #m =  month[index]\n",
    "        df = pd.read_csv(elem)\n",
    "        df.insert(1, 'month', month[index])\n",
    "        #df['month'] = m\n",
    "        final_df = final_df.append(df, ignore_index=True)\n",
    "        print(\"Parsing completed\")\n",
    "    \n",
    "    type_object = final_df.select_dtypes(include='object').columns.to_list()\n",
    "    type_object.remove('store_and_fwd_flag')\n",
    "    type_object.remove('month')\n",
    "    \n",
    "    for elem in type_object:\n",
    "        final_df[f\"{elem}\"] = pd.to_datetime(final_df[f\"{elem}\"], yearfirst=True, format=\"%Y/%m/%d %H:%M:%S\")\n",
    "    \n",
    "    final_df['month'] = pd.to_datetime(final_df['month'], format=\"%B\").dt.month  \n",
    "    \n",
    "    trip_duration_seconds = (final_df['tpep_dropoff_datetime'] - final_df['tpep_pickup_datetime']).astype('timedelta64[s]').astype('int')\n",
    "    trip_duration = trip_duration_seconds.apply(time_lapse)\n",
    "    \n",
    "    final_df.insert(4, 'trip_duration_seconds', trip_duration_seconds)\n",
    "    final_df.insert(5, 'trip_duration', trip_duration)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rolled-baltimore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asking for http content from https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
      "Filtering by year provided: 2020...\n",
      "html generated\n",
      "list of months requested: ('January', 'February', 'March')\n",
      "Checking month requested January vs months available in the html content...\n",
      "Month provided is valid. Filtering by month...\n",
      "Checking month requested February vs months available in the html content...\n",
      "Month provided is valid. Filtering by month...\n",
      "Checking month requested March vs months available in the html content...\n",
      "Month provided is valid. Filtering by month...\n",
      "Generating csv links table\n",
      "0    https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2020-01.csv\n",
      "4    https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2020-02.csv\n",
      "8    https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2020-03.csv\n",
      "Name: links, dtype: object\n",
      "Starting parsing process:\n",
      "Parsing csv https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2020-01.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/work/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3338: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing completed\n",
      "Parsing csv https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2020-02.csv\n",
      "Parsing completed\n",
      "Parsing csv https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2020-03.csv\n",
      "Parsing completed\n"
     ]
    }
   ],
   "source": [
    "yellowtaxis_2020= csv_to_df(2020, 'Yellow', 'January', 'February', 'March')\n",
    "name = \"2020_yellow_jan_feb_mar.csv\"\n",
    "yellowtaxis_2020.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "disciplinary-editor",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Stoping here",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2c1a50556316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Stoping here\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: Stoping here"
     ]
    }
   ],
   "source": [
    "raise ValueError(\"Stoping here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-authentication",
   "metadata": {},
   "source": [
    "# DataBase creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "#establishing the connection\n",
    "conn = psycopg2.connect(\n",
    "   database=\"postgres\", user='postgres', password='Snowdav3', host='127.0.0.1', port= '5432'\n",
    ")\n",
    "\n",
    "conn.autocommit = True\n",
    "\n",
    "#Creating a cursor object using the cursor() method\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#Preparing query to create a database\n",
    "sql = '''CREATE database taxis''';\n",
    "\n",
    "#Creating a database\n",
    "cursor.execute(sql)\n",
    "print(\"Database created successfully !\")\n",
    "\n",
    "#Closing the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-speaker",
   "metadata": {},
   "source": [
    "# DataBase conection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dic = {\n",
    "    \"host\"      : \"127.0.0.1\",\n",
    "    \"database\"  : \"taxis\",\n",
    "    \"user\"      : \"postgres\",\n",
    "    \"password\"  : \"Snowdav3\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(params_dic):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = psycopg2.connect(**params_dic)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1) \n",
    "    print('Connection succesful')\n",
    "    \n",
    "    return conn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-conservative",
   "metadata": {},
   "source": [
    "# Creating Table in the DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_table(table_name: str):\n",
    "    \n",
    "    conn = connect(param_dic)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    sql =f'''CREATE TABLE {table_name}(\n",
    "       VendorID float,\n",
    "       month int,\n",
    "       tpep_pickup_datetime timestamp,\n",
    "       tpep_dropoff_datetime timestamp,\n",
    "       trip_duration_seconds int,\n",
    "       trip_duration varchar,\n",
    "       passenger_count float,\n",
    "       trip_distance float,\n",
    "       RatecodeID float,\n",
    "       store_and_fwd_flag varchar,\n",
    "       PULocationID float,\n",
    "       DOLocationID float,\n",
    "       payment_type float,\n",
    "       fare_amount float,\n",
    "       extra float,\n",
    "       mta_tax float,\n",
    "       tip_amount float,\n",
    "       tolls_amount float,\n",
    "       improvement_surcharge float,\n",
    "       total_amount float,\n",
    "       congestion_surcharge float\n",
    "    );'''\n",
    "    \n",
    "    cursor.execute(sql)\n",
    "    print(\"Table created\")\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    print(\"Cursor object closed\")\n",
    "    conn.rollback()\n",
    "    print(f\"Closing {conn.info.dbname} database conection\")\n",
    "    conn.close()\n",
    "    print(\"Conection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "creating_table('yellowtaxis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-picking",
   "metadata": {},
   "source": [
    "# DataBase insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_batch(table: str, year: int, taxi_color: str, *month, page_size=100,):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "\n",
    "    df = csv_to_df(year, taxi_color, *month)\n",
    "    \n",
    "    print(\"Converting DataFrame rows into tuples\")\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL quert to execute\n",
    "    query  = \"INSERT INTO %s(%s) VALUES(%%s,%%s,%%s,%%s,%%s,%%s,%%s,%%s,%%s,%%s,%%s,%%s,%%s,%%s,%%s,%%s,%%s,%%s,%%s,%%s,%%s)\" % (table, cols)\n",
    "    conn = connect(param_dic)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        print(f\"Inserting values into the {table} table at {conn.info.dbname} database. Please wait, this may take a few minutes...\")\n",
    "        extras.execute_batch(cursor, query, tuples, page_size)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(f\"Batch executed succesfully, all dataframe values inserted into the {table} table at {cursor.connection}\")\n",
    "    \n",
    "    cursor.close()\n",
    "    print(\"Cursor object closed\")\n",
    "    conn.close()\n",
    "    print(f\"Conection {conn} closed\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_batch('yellowtaxis', 2020, 'Yellow', 'January', 'February', 'March')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-viewer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:work]",
   "language": "python",
   "name": "conda-env-work-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
